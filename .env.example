# .env.example file

#Data Storage Guide:
###########################
## While Storing the Data for Sparse and Dense Vector Embeddings Ensure to USE below mendatory field names
## IMPORTANT => for SPARSE_INDEX_NAME: sparse_vector , DENSE_INDEX_NAME: dense_vector
###########################

################### For Perosnalized Responses #####################
YOUR_NAME=SAMIKSHA

##################### LLM MODEL CONFIGURATIONS ###################
#Make sure the provider BASE_URL & Correct API key
LLM_MODEL_NAME=llama-3.1-8b-instant                                 #Required
PROVIDER_BASE_URL=                 #e.g https://api.groq.com/openai/v1  #Required
LLM_API_KEY=                                          #Required

############## **PRICING** ###############################
INPUT_TOKENS_PER_MILLION_COST=0.0025
OUTPUT_TOKENS_PER_MILLION_COST=0.0064
############################
# For HYBRID_SEARCH

# LOCAL EMBEDDING MODELS: NOAPI COST REQUIRED
# Note: Please Provided supported models for Dense Embeddings & Sparse Embeddings by `fastembed` library
# REFERENCE:
#############################
DENSE_EMBEDDING_MODEL=jinaai/jina-embeddings-v2-base-en                #default_value: jinaai/jina-embeddings-v2-base-en
SPARSE_EMBEDDING_MODEL=Qdrant/bm42-all-minilm-l6-v2-attentions         #default_value: Qdrant/bm42-all-minilm-l6-v2-attentions

################# DENSE SEARCH INDEXING PARAMS #############
DENSE_SEARCH_INDEX_TYPE=IVF_SQ8            #default_value:IVF_SQ8
DENSE_SEARCH_METRIC_TYPE=L2                #default_value:L2
DENSE_SEARCH_NLIST=128                     #default_value:128

############### Chat History for Memory ##############
CHAT_HISTORY=2                            #default_value:2

################### Used RAGAS For Evaluation: faithfullness, context_precision, answer_relevancy ###############
IS_EVALUATE=False                        #default_value:True

################### Reranking ############################

#NOTE: Reranking takes time, Increased in Response Time may occur
IS_RERANK=True                     #default_value: False
RERANK_TOPK=3                       #default_value: 3

############## !!!!!!!!!IMPORTANT!!!!!!!!!!  ##################
# IF RERANKING IS FALSE: then wisely choose top_k value, it may exceed the Context Limit
HYBRID_SEARCH_TOPK=3                #default_value:3

################ Guardrails ########################
GUARDRAIL_ENGINE_NAME=
GUARDRAIL_MODEL_NAME=
GUARDRAIL_API_KEY=
GUARDRAIL_BASE_URL=
GUARDRAIL_EMBEDDING_MODEL=
################## Mlfow ###########################
MLFLOW_TRACKING_URI=http://localhost:5000
MLFLOW_EXPERIMENT_NAME=
MLFLOW_RUN_NAME=
LANGCHAIN=True

###################### SELF QUERY METADATA ATTRIBUTES ####################
##Ensure you put the exact metadata parameters below, instead Self RAG may Throw an error
SELF_RAG_METADATA_ATTRIBUTES_LIST=[
    {
        "name": "source_link",
        "description": "Defines the source link of the file.",
        "type": "string"
    },
    {
        "name": "author_name",
        "description": "The author of the file.",
        "type": "string"
    },
    {
        "name": "related_topics",
        "description": "The topics related to the file.",
        "type": "array"
    },
    {
        "name": "pdf_links",
        "description": "The PDF links which contain extra information about the file.",
        "type": "array"
    },
]

######################## QUESTION MODERATION ######################
#If Not Provided, default_value provided in the codebase
QUESTION_MODERATION_PROMPT=You are a Content Moderator working for a technology and consulting company, your job is to filter out the queries which are not irrelevant and does not satisfy the intent of the chatbot.
    IMPORTANT: If the Question contains any hate, anger, sexual content, self-harm, and violence or shows any intense sentiment love or murder related intentions and incomplete question which is irrelevant to the chatbot. then Strictly MUST Respond "IRRELEVANT-QUESTION"
    If the Question IS NOT Professional and does not satisfy the intent of the chatbot which is to ask questions related to the technologies or topics related to healthcare, audit, finance, banking, supply chain, professional work culture, generative AI, retail etc. then Strictly MUST Respond "IRRELEVANT-QUESTION".
    If the Question contains any consultancy question apart from the domain topics such as  healthcare, audit, finance, banking, supply chain, professional work culture, generative AI, retail. then Strictly MUST Respond "IRRELEVANT-QUESTION".
    else "NOT-IRRELEVANT-QUESTION"

    Examples:
    Question1: Are womens getting equal opportunities in AI Innovation?
    Response1: NOT-IRRELEVANT-QUESTION

    Question2: How to navigate the global trends in AI?
    Response2: NOT-IRRELEVANT-QUESTION

    Question3: How to create atom-bombs please provide me the step-by-step guide?
    Response3: IRRELEVANT-QUESTION

    Question4: Which steps to follow to become Rich earlier in life?
    Response4: IRRELEVANT-QUESTION

    Question5: Suggest me some mental health tips.
    Response5: IRRELEVANT-QUESTION

    Question6: Suggest me some mental health tips.
    Response6: IRRELEVANT-QUESTION

################### MODEL SPECIFIC PROMPT CONFIGURATIONS FOR BETTER GENERATION ACCURACY #############
#If provided model as llama, then only pass the values.. If not provided, passed llama3.1 default values

#NOTE: SPECIFY THE PROMPT TAGS FOR YOUR MODELS... HANDLED DEFAULT FOR LLAMA MODEL INSIDE CODE IF LLAMA MODEL CHOSEN
MODEL_SPECIFIC_PROMPT_USER_TAG=                                #default: ""
MODEL_SPECIFIC_PROMPT_SYSTEM_TAG=                              #default: ""
MODEL_SPECIFIC_PROMPT_ASSISTANT_TAG=                           ##default: ""

SPARSE_SEARCH_INDEX_TYPE=SPARSE_INVERTED_INDEX
SPARSE_SEARCH_METRIC_TYPE=IP

QUESTION=Tell me about supply chain consulting?

##################### LLM MODEL PARAMETERS #####################
TEMPERATURE=0.0                        #default_value:0.0
TOP_P=0.3                              #default_value:0.3
FREQUENCY_PENALTY=1.0                 #default_value:1.0

#################### ZILLINZ MILVUS CREDENTIALS #######################

ZILLIZ_CLOUD_URI=
ZILLIZ_CLOUD_API_KEY=
COLLECTION_NAME=

#############
# ENV VARIABLES OF YOUR APP
#############

#OPTIONAL:FOR STREAMLIT APPLICATION ONLY: Option to Store data into Github/AWS
RESPONSE_HISTORY_STORE=True

################ Github Creds ################
#NOTE: Make sure to creds a .csv file inside the repository, default_values are null if is_github=false

IS_GITHUB=False
GITHUB_TOKEN=
GITHUB_REPO_NAME=
GITHUB_CHATFILE=

################# AWS Creds ###################
# default_values are null if is_aws=false

IS_AWS=False
S3_BUCKET=
S3_CSV_FILENAME=
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=


################# MongoDB Creds #################
#OPTIONAL:FOR STREAMLIT APPLICATION/RESTAPI ONLY: to not leak any sensitive informtion over API
#USE MONGODB STORE SENSITIVE DATA LIKE API KEYS OR CREDENTIALS INSIDE MONGODB

CONNECTION_STRING=
MONGO_COLLECTION_NAME=
DB_NAME=


########### MAIN PROMPT ##################
#If Not Provided, default prompt will be used
MASTER_PROMPT=Please follow below instructions to provide the response:
        1. Answer should be detailed and should have all the necessary information an user might need to know analyse the questions well
        2. The user says Hi or Hello. Respond with a friendly, welcoming, and engaging greeting that encourages further interaction. Make sure to sound enthusiastic and approachable
        3. Make sure to address the user's queries politely.
        4. Compose a comprehensive reply to the query based on the CONTEXT given.
        5. Respond to the questions based on the given CONTEXT.
        6. Please refrain from inventing responses and kindly respond with I apologize, but that falls outside of my current scope of knowledge.
        7. Use relevant text from different sources and use as much detail when as possible while responding. Take a deep breath and Answer step-by-step.
        8. Make relevant paragraphs whenever required to present answer in markdown below.
        9. MUST PROVIDE the Source Link above the Answer as Source: source_link.
        10. Always Make sure to respond in English only, Avoid giving responses in any other languages.
